Tengo esta gramatica:

<programa> ::= <lista_declaracion>

<lista_declaracion> ::= <lista_declaracion> <declaracion> | <declaracion>

<declaracion> ::= <declaracion_variable> | <lista_sentencias>

<declaracion_variable> ::= <tipo> <identificador> ";"

<tipo> ::= "int" | "real" | "void"

<lista_sentencias> ::= <lista_sentencias> <sentencia>| <vacio>

<sentencia> ::= <seleccion> | <iteracion> | <repeticion> | <sent_in> | <sent_out> | <asignacion>

<asignacion> ::= <identificador> <asignacion_op> <sent_expresion>

<asignacion_op> ::= "=" | "+=" | "-=" | "*=" | "/=" | "%="

<sent_expresion> ::= <expresion> ";" | ";"

<seleccion> ::= "if" <expresion> <sentencia> "end"
              | "if" <expresion> <sentencia> "else" <sentencia> "end"

<iteracion> ::= "while" <expresion> <sentencia> "end"

<repeticion> ::= "do" <sentencia> "until" <expresion>

<sent_in> ::= "cin" <identificador> ";"

<sent_out> ::= "cout" <expresion> ";"

<expresion> ::= <expresion_simple> <relacion_op> <expresion_simple> | <expresion_simple>

<relacion_op> ::= "<=" | "<" | ">" | ">=" | "==" | "!="

<expresion_simple> ::= <expresion_simple> <suma_op> <termino> | <termino>

<suma_op> ::= "+" | "-" | "++" | "--" 

<termino> ::= <termino> <mult_op> <factor> | <factor>

<mult_op> ::= "*" | "/" | "%"

<factor> ::= "(" <expresion> ")" | <numero> | <identificador>


Puedes desarrollarme un analizador sintactico completo en python en base a esa gramatica, el analizador debe generar un arbol sintactico como salida a un archivo de texto, ademas no debe pararse en los errores sintacticos solamente guardarlos a otro archivo y seguir. Tengo esta funcion para leer los tokens generados por un analizador lexico en un archivo resultados.txt. # Función para leer los tokens desde el archivo
def read_tokens(filename):
    with open(filename, 'r') as file:
        # Ignorar las dos primeras líneas
        file.readline()
        file.readline()
        # Leer los tokens desde el archivo
        tokens = []
        for line in file:
            token_type, value = line.strip().split('|')
            tokens.append(Token(token_type.strip(), value.strip(), len(tokens) + 3))
        return tokens